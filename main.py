#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI äº¤æ˜“ç³»ç»Ÿä¸»ç¨‹åº

åŠŸèƒ½ï¼š
1. æ•°æ®åŠ è½½ï¼šæ”¯æŒå¤šç§æ•°æ®æºï¼ˆCSVã€Yahoo Financeã€Binanceã€åˆæˆæ•°æ®ï¼‰
2. ç­–ç•¥æ‰§è¡Œï¼šå•æ—¶é—´å‘¨æœŸå’Œå¤šæ—¶é—´å‘¨æœŸåˆ†æ
3. ä¿¡å·è¿‡æ»¤ï¼šè´¨é‡è¯„åˆ†ã€é£é™©æ”¶ç›Šæ¯”ã€LLMè¯„åˆ†ç­‰
4. åˆçº¦äº¤æ˜“å¢å¼ºï¼šæ æ†ã€ä»“ä½ç®¡ç†ã€å¼ºåˆ¶å¹³ä»“ä¿æŠ¤
5. é«˜é¢‘äº¤æ˜“ï¼šå¤šæ—¶é—´å‘¨æœŸè¶…ä¹°/è¶…å–åˆ¤æ–­
6. å›æµ‹ç³»ç»Ÿï¼šæ”¯æŒåšå¤š/åšç©ºã€æ æ†ã€å¼ºåˆ¶å¹³ä»“
7. ç»“æœå¯è§†åŒ–ï¼šä»·æ ¼å›¾è¡¨ã€å›æµ‹ç»“æœã€æ€§èƒ½æŠ¥å‘Š

ä½œè€…: AI Trading System
ç‰ˆæœ¬: 4.2
"""
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional

import pandas as pd

# æ•°æ®å±‚å¯¼å…¥
from data.loader import gen_synthetic, load_csv
from data.market_data import fetch_market_data, get_popular_symbols

# ç­–ç•¥å±‚å¯¼å…¥
from strategy.strategy_runner import run_strategy

# å›æµ‹å±‚å¯¼å…¥
from backtest.simulator import simple_backtest

# é…ç½®å¯¼å…¥
from config import (
    DATA_SOURCE, DATA_PATH, MARKET_SYMBOL, MARKET_PERIOD, MARKET_INTERVAL,
    MARKET_TIMEFRAME, MARKET_LIMIT, USE_LLM, SYNTHETIC_DATA_SIZE, OUTPUT_DIR,
    BACKTEST_MAX_HOLD, BACKTEST_ATR_STOP_MULT, BACKTEST_ATR_TARGET_MULT, MIN_LLM_SCORE,
    USE_ADVANCED_TA, USE_ERIC_INDICATORS, MIN_RISK_REWARD, MIN_QUALITY_SCORE,
    MIN_CONFIRMATIONS, USE_SIGNAL_FILTER, BACKTEST_PARTIAL_TP_RATIO, BACKTEST_PARTIAL_TP_MULT,
    TRADING_MODE, SIGNAL_LOOKBACK_DAYS, MARKET_TYPE, USE_CACHED_DATA
)

# å·¥å…·å±‚å¯¼å…¥
from utils.logger import logger
from utils.visualization import plot_price_with_signals, plot_backtest_results, generate_report
from utils.config_validator import validate_config, print_config_summary

def main() -> int:
    """
    ä¸»å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„äº¤æ˜“ç­–ç•¥æµç¨‹
    
    æµç¨‹ï¼š
    1. é…ç½®éªŒè¯å’Œäº¤æ˜“æ¨¡å¼åº”ç”¨
    2. æ•°æ®åŠ è½½ï¼ˆCSV/Yahoo/Binance/åˆæˆæ•°æ®ï¼‰
    3. ç­–ç•¥æ‰§è¡Œï¼ˆå•æ—¶é—´å‘¨æœŸæˆ–å¤šæ—¶é—´å‘¨æœŸï¼‰
    4. åˆçº¦äº¤æ˜“ç­–ç•¥å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
    5. é«˜é¢‘äº¤æ˜“ç­–ç•¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    6. ä¿¡å·è¿‡æ»¤ï¼ˆè´¨é‡è¯„åˆ†ã€é£é™©æ”¶ç›Šæ¯”ç­‰ï¼‰
    7. å›æµ‹æ‰§è¡Œ
    8. ç»“æœå¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ
    
    Returns:
        int: é€€å‡ºç ï¼ˆ0è¡¨ç¤ºæˆåŠŸï¼Œé0è¡¨ç¤ºå¤±è´¥ï¼‰
    """
    try:
        logger.info("=" * 60)
        logger.info("AI äº¤æ˜“ç³»ç»Ÿ - å¯åŠ¨ä¸­")
        logger.info("=" * 60)
        
        # åº”ç”¨äº¤æ˜“æ¨¡å¼é…ç½®
        from utils.trading_mode import apply_trading_mode_config
        trading_config = apply_trading_mode_config()
        logger.info(f"äº¤æ˜“æ¨¡å¼: {TRADING_MODE}")
        logger.info(f"è‡ªåŠ¨è°ƒæ•´å‚æ•°: è´¨é‡è¯„åˆ†>={trading_config['min_quality_score']}, "
                   f"ç¡®è®¤æ•°>={trading_config['min_confirmations']}, "
                   f"LLMè¯„åˆ†>={trading_config['min_llm_score']}, "
                   f"ç›ˆäºæ¯”>={trading_config['min_risk_reward']}, "
                   f"æœ€å¤§æŒä»“={trading_config['max_hold']}")
        
        # éªŒè¯é…ç½®
        is_valid, errors = validate_config()
        if not is_valid:
            logger.error("Configuration validation failed:")
            for error in errors:
                logger.error(f"  - {error}")
            logger.error("Please fix the configuration errors and try again.")
            return 1
        
        print_config_summary()
        
        # 1. åŠ è½½æ•°æ®
        logger.info(f"æ•°æ®æº: {DATA_SOURCE}")
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¼“å­˜æ•°æ®
        output_dir = Path(OUTPUT_DIR)
        output_dir.mkdir(parents=True, exist_ok=True)
        cached_data_file = output_dir / 'sample_data.csv'
        use_cache = USE_CACHED_DATA and cached_data_file.exists()
        
        if use_cache:
            logger.info(f"å‘ç°ç¼“å­˜æ•°æ®æ–‡ä»¶: {cached_data_file}")
            logger.info("å°è¯•ä»ç¼“å­˜åŠ è½½æ•°æ®...")
            try:
                df = load_csv(str(cached_data_file))
                logger.info(f"âœ… æˆåŠŸä»ç¼“å­˜åŠ è½½ {len(df)} è¡Œæ•°æ®")
                logger.info(f"æ•°æ®æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                required_columns = ['open', 'high', 'low', 'close', 'volume']
                if all(col in df.columns for col in required_columns):
                    logger.info("ç¼“å­˜æ•°æ®éªŒè¯é€šè¿‡ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®è¿›è¡Œå›æ”¾")
                else:
                    logger.warning(f"ç¼“å­˜æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œå°†é‡æ–°è·å–æ•°æ®")
                    use_cache = False
            except Exception as e:
                logger.warning(f"åŠ è½½ç¼“å­˜æ•°æ®å¤±è´¥: {e}ï¼Œå°†é‡æ–°è·å–æ•°æ®")
                use_cache = False
        
        if not use_cache:
            # ä»æ•°æ®æºè·å–æ•°æ®
            if DATA_SOURCE == 'csv':
            if not DATA_PATH or not Path(DATA_PATH).exists():
                raise FileNotFoundError(f"DATA_SOURCE is 'csv' but DATA_PATH does not exist: {DATA_PATH}")
            logger.info(f"ä» CSV æ–‡ä»¶åŠ è½½æ•°æ®: {DATA_PATH}...")
            df = load_csv(DATA_PATH)
            logger.info(f"å·²åŠ è½½ {len(df)} è¡Œæ•°æ®ä» {DATA_PATH}")
            
        elif DATA_SOURCE == 'yahoo':
            logger.info(f"ä» Yahoo Finance è·å– {MARKET_SYMBOL} çš„æ•°æ®...")
            try:
                df = fetch_market_data(
                    symbol=MARKET_SYMBOL,
                    data_source='yahoo',
                    period=MARKET_PERIOD,
                    interval=MARKET_INTERVAL
                )
                logger.info(f"å·²ä» Yahoo Finance è·å– {len(df)} è¡Œæ•°æ®")
            except (ValueError, Exception) as e:
                error_msg = str(e)
                logger.error(f"ä» Yahoo Finance è·å–æ•°æ®å¤±è´¥: {error_msg}")
                # å¦‚æœæ˜¯åŠ å¯†è´§å¸ï¼Œæä¾›è‡ªåŠ¨é™çº§åˆ° Binance çš„å»ºè®®
                is_crypto = any(x in MARKET_SYMBOL.upper() for x in ['BTC', 'ETH', 'USD', 'USDT'])
                if is_crypto:
                    logger.error("=" * 60)
                    logger.error("Yahoo Finance å¯¹åŠ å¯†è´§å¸æ”¯æŒä¸ç¨³å®šï¼")
                    logger.error("=" * 60)
                    logger.info("æ¨èä½¿ç”¨ Binance è·å–åŠ å¯†è´§å¸æ•°æ®ï¼š")
                    binance_symbol = MARKET_SYMBOL.replace('-USD', '/USDT').replace('-', '/')
                    logger.info(f"  DATA_SOURCE=binance MARKET_SYMBOL={binance_symbol} MARKET_TIMEFRAME=1h")
                    logger.info("")
                    logger.info("æˆ–è€…ä½¿ç”¨è‚¡ç¥¨æ•°æ®æµ‹è¯•ï¼š")
                    logger.info(f"  DATA_SOURCE=yahoo MARKET_SYMBOL=AAPL MARKET_PERIOD=3mo MARKET_INTERVAL=1d")
                    logger.info("")
                    logger.info("æˆ–è€…ä½¿ç”¨åˆæˆæ•°æ®ï¼š")
                    logger.info(f"  DATA_SOURCE=synthetic")
                    logger.error("=" * 60)
                raise
            
        elif DATA_SOURCE == 'binance':
            logger.info(f"ä» Binance è·å– {MARKET_SYMBOL} çš„æ•°æ®...")
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è·å–6ä¸ªæœˆæ•°æ®ï¼ˆç”¨äºå›æµ‹ï¼‰
            backtest_months = int(os.getenv('BACKTEST_MONTHS', '0'))  # 0è¡¨ç¤ºä½¿ç”¨é»˜è®¤limit
            if backtest_months > 0:
                logger.info(f"å›æµ‹æ¨¡å¼ï¼šè·å– {backtest_months} ä¸ªæœˆçš„æ•°æ®...")
                from data.market_data import fetch_binance_data
                df = fetch_binance_data(
                    symbol=MARKET_SYMBOL,
                    timeframe=MARKET_TIMEFRAME,
                    months=backtest_months
                )
            else:
                df = fetch_market_data(
                    symbol=MARKET_SYMBOL,
                    data_source='binance',
                    timeframe=MARKET_TIMEFRAME,
                    limit=MARKET_LIMIT
                )
            logger.info(f"å·²ä» Binance è·å– {len(df)} è¡Œæ•°æ®")
            
            # éªŒè¯æ•°æ®æ—¶é—´èŒƒå›´
            if isinstance(df.index, pd.DatetimeIndex) and len(df) > 0:
                time_span = (df.index[-1] - df.index[0]).days
                logger.info(f"æ•°æ®æ—¶é—´è·¨åº¦: {time_span} å¤©ï¼ˆçº¦ {time_span/30:.1f} ä¸ªæœˆï¼‰")
            
        else:  # synthetic
            logger.info(f"ç”Ÿæˆåˆæˆæ•°æ® (å¤§å°={SYNTHETIC_DATA_SIZE})...")
            df = gen_synthetic(SYNTHETIC_DATA_SIZE)
            logger.info(f"å·²ç”Ÿæˆ {len(df)} è¡Œåˆæˆæ•°æ®")
        
        # 2. å¤šæ—¶é—´å‘¨æœŸç»¼åˆåˆ†æï¼ˆæŸ¥è¯¢è¿‡å¾€7å¤©çš„è¡Œæƒ…æ•°æ®ï¼Œåˆ†åˆ«è®¡ç®—1å°æ—¶ã€4å°æ—¶ã€å¤©çº§çš„Kçº¿ï¼‰
        logger.info("=" * 60)
        logger.info("å¼€å§‹å¤šæ—¶é—´å‘¨æœŸç»¼åˆåˆ†æ")
        logger.info("=" * 60)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå›æµ‹æ¨¡å¼ï¼ˆéœ€è¦è‡³å°‘6ä¸ªæœˆæ•°æ®å’Œ200+äº¤æ˜“ï¼‰
        backtest_mode = os.getenv('BACKTEST_MODE', 'False').lower() == 'true'
        backtest_months = int(os.getenv('BACKTEST_MONTHS', '0'))
        
        # å¦‚æœè®¾ç½®äº†BACKTEST_MONTHSï¼Œè‡ªåŠ¨å¯ç”¨å›æµ‹æ¨¡å¼
        if backtest_months > 0:
            backtest_mode = True
            logger.info(f"å›æµ‹æ¨¡å¼ï¼šç›®æ ‡ {backtest_months} ä¸ªæœˆæ•°æ®ï¼Œè‡³å°‘ 200+ ç¬”äº¤æ˜“")
            # å›æµ‹æ¨¡å¼ä¸‹ç¦ç”¨å¤šæ—¶é—´å‘¨æœŸåˆ†æï¼ˆä¼šäº§ç”Ÿæ›´å¤šä¿¡å·ï¼‰
            use_multi_timeframe = False
            logger.info("å›æµ‹æ¨¡å¼ï¼šç¦ç”¨å¤šæ—¶é—´å‘¨æœŸåˆ†æï¼Œä½¿ç”¨å•æ—¶é—´å‘¨æœŸä»¥äº§ç”Ÿæ›´å¤šäº¤æ˜“ä¿¡å·")
        else:
            use_multi_timeframe = os.getenv('USE_MULTI_TIMEFRAME', 'True').lower() == 'true'
        
        min_timeframe_confirmations = int(os.getenv('MIN_TIMEFRAME_CONFIRMATIONS', '2'))
        
        if use_multi_timeframe and DATA_SOURCE in ['binance', 'yahoo']:
            from strategy.multi_timeframe_analyzer import run_multi_timeframe_strategy
            
            # è¿è¡Œå¤šæ—¶é—´å‘¨æœŸåˆ†æ
            multi_timeframe_data, combined_signals = run_multi_timeframe_strategy(
                symbol=MARKET_SYMBOL,
                data_source=DATA_SOURCE,
                lookback_days=SIGNAL_LOOKBACK_DAYS,
                min_confirmations=min_timeframe_confirmations,
                use_advanced_ta=USE_ADVANCED_TA,
                use_eric_indicators=USE_ERIC_INDICATORS
            )
            
            if combined_signals:
                logger.info(f"å¤šæ—¶é—´å‘¨æœŸåˆ†ææ‰¾åˆ° {len(combined_signals)} ä¸ªç¡®è®¤ä¿¡å·")
                # ä½¿ç”¨1hæ•°æ®ä½œä¸ºä¸»æ•°æ®ï¼ˆç”¨äºåç»­åˆ†æå’Œå›æµ‹ï¼‰
                if '1h' in multi_timeframe_data:
                    df = multi_timeframe_data['1h']
                else:
                    # å¦‚æœæ²¡æœ‰1hæ•°æ®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ—¶é—´å‘¨æœŸ
                    df = list(multi_timeframe_data.values())[0] if multi_timeframe_data else df
                
                # å°†å¤šæ—¶é—´å‘¨æœŸç¡®è®¤çš„ä¿¡å·è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œå¹¶è¿›è¡ŒLLMåˆ†æï¼ˆå¹¶å‘å¤„ç†ï¼‰
                enhanced = []
                from strategy.strategy_runner import build_feature_packet
                from ai_agent.signal_interpret import interpret_with_llm
                from config import LLM_PROVIDER, DEEPSEEK_MODEL, OPENAI_MODEL, OPENAI_TEMPERATURE, OPENAI_MAX_TOKENS
                from concurrent.futures import ThreadPoolExecutor, as_completed
                
                # å‡†å¤‡æ‰€æœ‰ä¿¡å·çš„æ•°æ®
                signal_data_list = []
                for i, combined_signal in enumerate(combined_signals):
                    base_signal = combined_signal['base_signal']
                    signal_idx = base_signal.get('idx', -1)
                    
                    if signal_idx >= 0 and signal_idx < len(df):
                        packet = build_feature_packet(df, signal_idx)
                        signal_time = None
                        if isinstance(df.index, pd.DatetimeIndex) and signal_idx < len(df.index):
                            signal_time = df.index[signal_idx]
                        
                        signal_data_list.append({
                            'index': i,
                            'combined_signal': combined_signal,
                            'base_signal': base_signal,
                            'packet': packet,
                            'signal_time': signal_time
                        })
                
                # å¹¶å‘å¤„ç†LLMè°ƒç”¨
                model = DEEPSEEK_MODEL if LLM_PROVIDER == 'deepseek' else OPENAI_MODEL
                from config import LLM_CONCURRENT_WORKERS
                max_workers = LLM_CONCURRENT_WORKERS
                
                def process_multi_timeframe_signal(signal_data):
                    """å¤„ç†å•ä¸ªå¤šæ—¶é—´å‘¨æœŸä¿¡å·çš„LLMè°ƒç”¨"""
                    i = signal_data['index']
                    combined_signal = signal_data['combined_signal']
                    base_signal = signal_data['base_signal']
                    packet = signal_data['packet']
                    signal_time = signal_data['signal_time']
                    
                    try:
                        llm_out = interpret_with_llm(
                            packet,
                            provider=LLM_PROVIDER,
                            model=model,
                            use_llm=USE_LLM,
                            temperature=OPENAI_TEMPERATURE,
                            max_tokens=OPENAI_MAX_TOKENS
                        )
                    except Exception as e:
                        error_msg = str(e)
                        error_type = type(e).__name__
                        logger.warning(f"LLMåˆ†æå¤±è´¥ (ä¿¡å· {i+1}/{len(combined_signals)}): {error_type}: {error_msg}ï¼Œä½¿ç”¨fallback")
                        try:
                            llm_out = interpret_with_llm(packet, provider=LLM_PROVIDER, model=model, use_llm=False)
                        except Exception as fallback_error:
                            logger.error(f"Fallbackä¹Ÿå¤±è´¥: {fallback_error}")
                            llm_out = {
                                'trend_structure': 'Neutral',
                                'signal': 'Neutral',
                                'score': 0,
                                'confidence': 'Low',
                                'explanation': 'Error in LLM interpretation',
                                'risk': 'Unknown'
                            }
                    
                    return {
                        'index': i,
                        'rule': base_signal,
                        'feature_packet': packet,
                        'llm': llm_out,
                        'signal_time': signal_time.isoformat() if signal_time else None,
                        'multi_timeframe': {
                            'confirmations': combined_signal['confirmed_timeframes'],
                            'confirmation_count': combined_signal['confirmation_count']
                        }
                    }
                
                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
                if len(signal_data_list) > 0:
                    logger.info(f"ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹å¤„ç† {len(signal_data_list)} ä¸ªå¤šæ—¶é—´å‘¨æœŸä¿¡å·çš„LLMåˆ†æ...")
                    with ThreadPoolExecutor(max_workers=max_workers) as executor:
                        future_to_signal = {executor.submit(process_multi_timeframe_signal, signal_data): signal_data 
                                           for signal_data in signal_data_list}
                        
                        completed = 0
                        results = {}
                        for future in as_completed(future_to_signal):
                            completed += 1
                            try:
                                result = future.result()
                                results[result['index']] = result
                            except Exception as e:
                                signal_data = future_to_signal[future]
                                logger.error(f"å¤„ç†ä¿¡å· {signal_data['index']+1} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                                results[signal_data['index']] = {
                                    'index': signal_data['index'],
                                    'rule': signal_data['base_signal'],
                                    'feature_packet': signal_data['packet'],
                                    'llm': {
                                        'trend_structure': 'Neutral',
                                        'signal': 'Neutral',
                                        'score': 0,
                                        'confidence': 'Low',
                                        'explanation': 'Error in processing',
                                        'risk': 'Unknown'
                                    },
                                    'signal_time': signal_data['signal_time'].isoformat() if signal_data['signal_time'] else None,
                                    'multi_timeframe': {
                                        'confirmations': signal_data['combined_signal']['confirmed_timeframes'],
                                        'confirmation_count': signal_data['combined_signal']['confirmation_count']
                                    }
                                }
                            
                            if completed % 10 == 0 or completed == len(signal_data_list):
                                logger.info(f"å·²å¤„ç† {completed}/{len(signal_data_list)} ä¸ªå¤šæ—¶é—´å‘¨æœŸä¿¡å·...")
                        
                        # æŒ‰åŸå§‹é¡ºåºæ’åºç»“æœ
                        enhanced = [results[i] for i in sorted(results.keys())]
                
                logger.info(f"è½¬æ¢åå…±æœ‰ {len(enhanced)} ä¸ªå¤šæ—¶é—´å‘¨æœŸç¡®è®¤çš„ä¿¡å·ï¼ˆå·²è¿›è¡ŒLLMåˆ†æï¼‰")
            else:
                logger.warning("å¤šæ—¶é—´å‘¨æœŸåˆ†ææœªæ‰¾åˆ°ç¡®è®¤ä¿¡å·ï¼Œä½¿ç”¨å•æ—¶é—´å‘¨æœŸåˆ†æ")
                # å›é€€åˆ°å•æ—¶é—´å‘¨æœŸåˆ†æ
                lookback_days_for_strategy = None if backtest_mode else SIGNAL_LOOKBACK_DAYS
                df, enhanced = run_strategy(df, use_llm=USE_LLM, use_advanced_ta=USE_ADVANCED_TA, 
                                           use_eric_indicators=USE_ERIC_INDICATORS, lookback_days=lookback_days_for_strategy)
        else:
            # å•æ—¶é—´å‘¨æœŸåˆ†æï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            logger.info(f"è¿è¡Œå•æ—¶é—´å‘¨æœŸç­–ç•¥ (ä½¿ç”¨LLM={USE_LLM}, ä½¿ç”¨é«˜çº§æŒ‡æ ‡={USE_ADVANCED_TA}, ä½¿ç”¨EricæŒ‡æ ‡={USE_ERIC_INDICATORS})...")
            # å›æµ‹æ¨¡å¼ï¼šåˆ†æå…¨éƒ¨æ•°æ®ï¼›æ­£å¸¸æ¨¡å¼ï¼šåªåˆ†ææœ€è¿‘Nå¤©
            lookback_days_for_strategy = None if backtest_mode else SIGNAL_LOOKBACK_DAYS
            df, enhanced = run_strategy(df, use_llm=USE_LLM, use_advanced_ta=USE_ADVANCED_TA, 
                                       use_eric_indicators=USE_ERIC_INDICATORS, lookback_days=lookback_days_for_strategy)
        
        # 2.5. é«˜é¢‘äº¤æ˜“ç­–ç•¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        use_high_frequency = os.getenv('USE_HIGH_FREQUENCY', 'True').lower() == 'true'
        if use_high_frequency and DATA_SOURCE in ['binance', 'yahoo'] and not backtest_mode:
            logger.info("=" * 60)
            logger.info("å¼€å§‹é«˜é¢‘äº¤æ˜“ç­–ç•¥åˆ†æ")
            logger.info("=" * 60)
            
            from strategy.high_frequency_strategy import detect_high_frequency_signals, enhance_with_5m_entry
            from data.market_data import fetch_market_data, fetch_binance_data
            
            # è·å–å¤šæ—¶é—´å‘¨æœŸæ•°æ®
            df_daily = None
            df_4h = None
            df_1h = df.copy()  # ä½¿ç”¨å½“å‰1å°æ—¶æ•°æ®
            df_5m = None
            
            try:
                # è·å–æ—¥çº¿æ•°æ®
                if DATA_SOURCE == 'binance':
                    df_daily = fetch_binance_data(
                        symbol=MARKET_SYMBOL,
                        timeframe='1d',
                        limit=100,
                        market_type=MARKET_TYPE
                    )
                    # è·å–4å°æ—¶æ•°æ®
                    df_4h = fetch_binance_data(
                        symbol=MARKET_SYMBOL,
                        timeframe='4h',
                        limit=200,
                        market_type=MARKET_TYPE
                    )
                    # è·å–5åˆ†é’Ÿæ•°æ®ï¼ˆç”¨äºä¼˜åŒ–å…¥åœºç‚¹ï¼‰
                    df_5m = fetch_binance_data(
                        symbol=MARKET_SYMBOL,
                        timeframe='5m',
                        limit=500,
                        market_type=MARKET_TYPE
                    )
                elif DATA_SOURCE == 'yahoo':
                    # Yahoo Finance æ•°æ®
                    df_daily = fetch_market_data(
                        symbol=MARKET_SYMBOL,
                        data_source='yahoo',
                        period='6mo',
                        interval='1d'
                    )
                    df_4h = fetch_market_data(
                        symbol=MARKET_SYMBOL,
                        data_source='yahoo',
                        period='3mo',
                        interval='4h'
                    )
                    # Yahoo Finance æœ€å°æ”¯æŒ5åˆ†é’Ÿ
                    df_5m = fetch_market_data(
                        symbol=MARKET_SYMBOL,
                        data_source='yahoo',
                        period='5d',
                        interval='5m'
                    )
                
                # ç¡®ä¿æ•°æ®æœ‰å¿…è¦çš„æŒ‡æ ‡
                from features.ta_basic import add_basic_ta
                if df_daily is not None and len(df_daily) > 0:
                    df_daily = add_basic_ta(df_daily)
                if df_4h is not None and len(df_4h) > 0:
                    df_4h = add_basic_ta(df_4h)
                if df_1h is not None and len(df_1h) > 0:
                    df_1h = add_basic_ta(df_1h)
                if df_5m is not None and len(df_5m) > 0:
                    df_5m = add_basic_ta(df_5m)
                
                # æ£€æµ‹é«˜é¢‘äº¤æ˜“ä¿¡å·
                min_consecutive_overbought = int(os.getenv('HF_MIN_CONSECUTIVE_OVERBOUGHT', '3'))
                min_consecutive_oversold = int(os.getenv('HF_MIN_CONSECUTIVE_OVERSOLD', '3'))
                
                hf_signals = detect_high_frequency_signals(
                    df_daily=df_daily,
                    df_4h=df_4h,
                    df_1h=df_1h,
                    min_consecutive_overbought=min_consecutive_overbought,
                    min_consecutive_oversold=min_consecutive_oversold
                )
                
                if hf_signals:
                    logger.info(f"é«˜é¢‘äº¤æ˜“ç­–ç•¥æ‰¾åˆ° {len(hf_signals)} ä¸ªä¿¡å·")
                    
                    # ä½¿ç”¨5åˆ†é’Ÿçº¿ä¼˜åŒ–å…¥åœºç‚¹
                    enhanced_hf_signals = []
                    for signal in hf_signals:
                        enhanced_signal = enhance_with_5m_entry(signal, df_5m)
                        
                        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                        from strategy.strategy_runner import build_feature_packet
                        from ai_agent.signal_interpret import interpret_with_llm
                        
                        entry_idx = enhanced_signal.get('entry_idx', -1)
                        if entry_idx >= 0 and entry_idx < len(df_1h):
                            packet = build_feature_packet(df_1h, entry_idx)
                            
                            # LLMåˆ†æï¼ˆå¯é€‰ï¼‰
                            if USE_LLM:
                                try:
                                    llm_out = interpret_with_llm(
                                        packet,
                                        provider=LLM_PROVIDER,
                                        model=DEEPSEEK_MODEL if LLM_PROVIDER == 'deepseek' else OPENAI_MODEL,
                                        use_llm=USE_LLM,
                                        temperature=OPENAI_TEMPERATURE,
                                        max_tokens=OPENAI_MAX_TOKENS
                                    )
                                except:
                                    llm_out = {
                                        'trend_structure': 'Neutral',
                                        'signal': enhanced_signal['direction'],
                                        'score': enhanced_signal.get('score', 50),
                                        'confidence': 'Medium',
                                        'explanation': f"é«˜é¢‘äº¤æ˜“ä¿¡å·: {', '.join(enhanced_signal.get('reasons', []))}",
                                        'risk': []
                                    }
                            else:
                                llm_out = {
                                    'trend_structure': 'Neutral',
                                    'signal': enhanced_signal['direction'],
                                    'score': enhanced_signal.get('score', 50),
                                    'confidence': 'Medium',
                                    'explanation': f"é«˜é¢‘äº¤æ˜“ä¿¡å·: {', '.join(enhanced_signal.get('reasons', []))}",
                                    'risk': []
                                }
                            
                            # æ„å»ºæ ‡å‡†ä¿¡å·æ ¼å¼
                            standard_signal = {
                                'rule': {
                                    'type': 'high_frequency',
                                    'idx': entry_idx,
                                    'score': enhanced_signal.get('score', 50),
                                    'confidence': 'high'
                                },
                                'feature_packet': packet,
                                'llm': llm_out,
                                'signal_time': enhanced_signal.get('entry_time').isoformat() if enhanced_signal.get('entry_time') else None,
                                'structure_label': enhanced_signal.get('higher_timeframe_signal', {}).get('signal_type', 'HIGH_FREQ'),
                                'hf_signal': enhanced_signal  # ä¿ç•™é«˜é¢‘ä¿¡å·åŸå§‹ä¿¡æ¯
                            }
                            
                            enhanced_hf_signals.append(standard_signal)
                    
                    # åˆå¹¶åˆ°ä¸»ä¿¡å·åˆ—è¡¨
                    if enhanced:
                        enhanced.extend(enhanced_hf_signals)
                    else:
                        enhanced = enhanced_hf_signals
                    
                    logger.info(f"å·²æ·»åŠ  {len(enhanced_hf_signals)} ä¸ªé«˜é¢‘äº¤æ˜“ä¿¡å·ï¼Œæ€»ä¿¡å·æ•°: {len(enhanced)}")
                else:
                    logger.info("é«˜é¢‘äº¤æ˜“ç­–ç•¥æœªæ‰¾åˆ°ä¿¡å·")
                    
            except Exception as e:
                logger.warning(f"é«˜é¢‘äº¤æ˜“ç­–ç•¥æ‰§è¡Œå¤±è´¥: {e}ï¼Œç»§ç»­ä½¿ç”¨åŸæœ‰ä¿¡å·")
                import traceback
                logger.debug(traceback.format_exc())
        
        if backtest_mode:
            logger.info(f"æ£€æµ‹åˆ° {len(enhanced)} ä¸ªä¿¡å·ï¼ˆå…¨é‡æ•°æ®å›æµ‹ï¼‰")
        else:
            logger.info(f"æ£€æµ‹åˆ° {len(enhanced)} ä¸ªä¿¡å·ï¼ˆæœ€è¿‘ {SIGNAL_LOOKBACK_DAYS} å¤©å†…ï¼‰")
        
        # 2.4. åˆçº¦äº¤æ˜“ç­–ç•¥å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if os.getenv('FUTURES_USE_ENHANCED_STRATEGY', 'True').lower() == 'true' and MARKET_TYPE == 'future':
            logger.info("=" * 60)
            logger.info("åº”ç”¨åˆçº¦äº¤æ˜“ç­–ç•¥å¢å¼º")
            logger.info("=" * 60)
            
            from strategy.futures_strategy import enhance_long_signal_for_futures, enhance_short_signal_for_futures
            from config import FUTURES_LEVERAGE, FUTURES_RISK_PER_TRADE
            
            enhanced_with_futures = []
            for signal in enhanced:
                rule = signal.get('rule', {})
                signal_idx = rule.get('idx', -1)
                llm = signal.get('llm', {})
                signal_direction = llm.get('signal', 'Neutral')
                
                if signal_idx >= 0 and signal_idx < len(df):
                    if signal_direction == 'Long':
                        enhanced_signal = enhance_long_signal_for_futures(
                            signal, df, signal_idx,
                            leverage=FUTURES_LEVERAGE,
                            risk_per_trade=FUTURES_RISK_PER_TRADE
                        )
                    elif signal_direction == 'Short':
                        enhanced_signal = enhance_short_signal_for_futures(
                            signal, df, signal_idx,
                            leverage=FUTURES_LEVERAGE,
                            risk_per_trade=FUTURES_RISK_PER_TRADE
                        )
                    else:
                        enhanced_signal = signal
                    
                    enhanced_with_futures.append(enhanced_signal)
                else:
                    enhanced_with_futures.append(signal)
            
            enhanced = enhanced_with_futures
            logger.info(f"å·²ä¸º {len(enhanced)} ä¸ªä¿¡å·åº”ç”¨åˆçº¦äº¤æ˜“ç­–ç•¥å¢å¼º")
        
        # 2.5. åº”ç”¨ä¿¡å·è¿‡æ»¤å™¨ï¼ˆæå‡èƒœç‡ï¼‰
        # å›æµ‹æ¨¡å¼ä¸‹ï¼Œé™ä½é˜ˆå€¼ä»¥äº§ç”Ÿæ›´å¤šäº¤æ˜“
        if USE_SIGNAL_FILTER:
            from strategy.signal_filter import apply_signal_filters
            # ä½¿ç”¨äº¤æ˜“æ¨¡å¼é…ç½®çš„å‚æ•°ï¼ˆå¦‚æœå·²åº”ç”¨ï¼‰
            from utils.trading_mode import get_trading_mode_config
            data_interval = MARKET_INTERVAL if DATA_SOURCE in ['yahoo', 'csv'] else MARKET_TIMEFRAME
            mode_config = get_trading_mode_config(TRADING_MODE, data_interval)
            
            # å›æµ‹æ¨¡å¼ä¸‹ï¼Œé™ä½é˜ˆå€¼ä»¥äº§ç”Ÿæ›´å¤šäº¤æ˜“
            if backtest_mode:
                logger.info("å›æµ‹æ¨¡å¼ï¼šå¤§å¹…é™ä½è¿‡æ»¤é˜ˆå€¼ä»¥äº§ç”Ÿæ›´å¤šäº¤æ˜“ä¿¡å·ï¼ˆç›®æ ‡ï¼š200+äº¤æ˜“ï¼‰")
                # ä½¿ç”¨éå¸¸å®½æ¾çš„é˜ˆå€¼ï¼Œä»¥äº§ç”Ÿæ›´å¤šäº¤æ˜“
                min_quality = int(os.getenv('MIN_QUALITY_SCORE', '10'))  # é™ä½åˆ°10ï¼ˆä»20ï¼‰
                min_conf = int(os.getenv('MIN_CONFIRMATIONS', '1'))  # ä¿æŒ1
                min_rr = float(os.getenv('MIN_RISK_REWARD', '1.5'))  # ä¿æŒ1.5ï¼ˆç”¨æˆ·è¦æ±‚ï¼‰
                min_llm = int(os.getenv('MIN_LLM_SCORE', '10'))  # é™ä½åˆ°10ï¼ˆä»20ï¼‰
                logger.info(f"å›æµ‹æ¨¡å¼è¿‡æ»¤é˜ˆå€¼: è´¨é‡è¯„åˆ†>={min_quality}, ç¡®è®¤æ•°>={min_conf}, ç›ˆäºæ¯”>={min_rr}, LLMè¯„åˆ†>={min_llm}")
            else:
                # ä½¿ç”¨äº¤æ˜“æ¨¡å¼é…ç½®çš„å‚æ•°ï¼Œä½†å…è®¸ç¯å¢ƒå˜é‡è¦†ç›–
                min_quality = int(os.getenv('MIN_QUALITY_SCORE', mode_config['min_quality_score']))
                min_conf = int(os.getenv('MIN_CONFIRMATIONS', mode_config['min_confirmations']))
                min_rr = float(os.getenv('MIN_RISK_REWARD', mode_config['min_risk_reward']))
                min_llm = int(os.getenv('MIN_LLM_SCORE', mode_config['min_llm_score']))
            
            enhanced = apply_signal_filters(
                df, enhanced,
                min_quality_score=min_quality,
                min_confirmations=min_conf,
                min_risk_reward=min_rr,
                min_llm_score=min_llm
            )
            logger.info(f"ä¿¡å·è¿‡æ»¤åå‰©ä½™ {len(enhanced)} ä¸ªé«˜è´¨é‡ä¿¡å·")
            
            # å›æµ‹æ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡äº¤æ˜“æ•°é‡
            if backtest_mode and len(enhanced) < 200:
                logger.warning(f"âš ï¸ å½“å‰åªæœ‰ {len(enhanced)} ä¸ªä¿¡å·ï¼Œæœªè¾¾åˆ° 200+ çš„ç›®æ ‡")
                logger.warning("å»ºè®®è¿›ä¸€æ­¥é™ä½é˜ˆå€¼ï¼š")
                logger.warning(f"  MIN_QUALITY_SCORE={max(20, min_quality-10)}")
                logger.warning(f"  MIN_LLM_SCORE={max(20, min_llm-10)}")
                logger.warning(f"  MIN_RISK_REWARD={max(1.0, min_rr-0.1):.1f}")
        
        # 3. å¤§è¶‹åŠ¿ä¿¡å·ç¡®è®¤åï¼Œåœ¨å°å‘¨æœŸæŸ¥æ‰¾å…·ä½“å¼€å•æ—¶é—´
        # æµç¨‹ï¼šå°æ—¶çº§æ•°æ®æ‰¾åˆ°å¤§è¶‹åŠ¿ä¿¡å· -> é‡æ–°æŸ¥è¯¢ä¿¡å·æ—¶é—´èŒƒå›´å†…çš„5åˆ†é’Ÿçº§æ•°æ® -> æ‰¾å…·ä½“å¼€å•æ—¶é—´
        logger.info("=" * 60)
        logger.info("ğŸ“ˆ å¤§è¶‹åŠ¿ä¿¡å·å·²ç¡®è®¤ï¼ˆå°æ—¶çº§ï¼‰ï¼Œå¼€å§‹åœ¨å°å‘¨æœŸæŸ¥æ‰¾å…·ä½“å¼€å•æ—¶é—´...")
        logger.info("=" * 60)
        from utils.entry_finder import find_best_entry_point_3m
        from datetime import datetime
        
        for signal in enhanced:
            # è·å–ä¿¡å·ä¿¡æ¯
            rule = signal.get('rule', {})
            llm = signal.get('llm', {})
            signal_idx = rule.get('idx', -1)
            signal_direction = llm.get('signal', 'Neutral')
            
            # åªå¤„ç† Long ä¿¡å·
            if signal_direction != 'Long':
                continue
            
            # è·å–ä¿¡å·æ—¶é—´å’Œä»·æ ¼
            signal_time = None
            signal_price = None
            
            if 'signal_time' in signal and signal['signal_time']:
                try:
                    signal_time = pd.to_datetime(signal['signal_time'])
                except:
                    pass
            
            if signal_time is None and signal_idx >= 0 and signal_idx < len(df):
                if isinstance(df.index, pd.DatetimeIndex):
                    signal_time = df.index[signal_idx]
                else:
                    continue
            
            if signal_time is None:
                continue
            
            signal_price = df['close'].iloc[signal_idx] if signal_idx < len(df) else None
            if signal_price is None:
                continue
            
            # å¤§è¶‹åŠ¿ä¿¡å·ç¡®è®¤åï¼Œé‡æ–°æŸ¥è¯¢5åˆ†é’Ÿçº§æ•°æ®ï¼Œæ‰¾å…·ä½“å¼€å•æ—¶é—´
            # æŸ¥è¯¢èŒƒå›´ï¼šä¿¡å·æ—¶é—´å‰å8å°æ—¶å†…
            logger.info(f"ğŸ” ä¿¡å· {signal_idx}: é‡æ–°æŸ¥è¯¢5åˆ†é’Ÿçº§æ•°æ®ï¼ŒæŸ¥æ‰¾å¼€å•æ—¶é—´ï¼ˆä¿¡å·æ—¶é—´: {signal_time}ï¼‰")
            entry_point = find_best_entry_point_3m(
                signal_time=signal_time,
                signal_price=signal_price,
                signal_direction=signal_direction
            )
            
            if entry_point:
                # å°†å…¥åœºæ—¶é—´è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´å¹¶æ ¼å¼åŒ–
                from utils.time_utils import to_beijing_time
                entry_time_str = to_beijing_time(entry_point['entry_time'])
                
                # ç›´æ¥ä½¿ç”¨ä¸­æ–‡å…³é”®å­—ï¼Œé¿å…ç¿»è¯‘æ­§ä¹‰
                signal['best_entry_3m'] = {
                    'å…¥åœºæ—¶é—´': entry_time_str,
                    'å…¥åœºä»·æ ¼': entry_point['entry_price'],
                    'å…¥åœºåŸå› ': entry_point['entry_reason'],
                    'å…¥åœºè¯„åˆ†': entry_point['entry_score']
                }
                logger.info(f"ä¿¡å· {signal_idx}: æ‰¾åˆ°çŸ­å‘¨æœŸå…¥åœºç‚¹ï¼Œä»·æ ¼={entry_point['entry_price']:.2f}, æ—¶é—´={entry_time_str}")
        
        # 3.5. ä¿å­˜ä¿¡å·æ—¥å¿—ï¼ˆä½¿ç”¨ä¸­æ–‡å…³é”®å­—ï¼Œå¹¶è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼‰
        output_dir = Path(OUTPUT_DIR)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        signals_file = output_dir / 'signals_log.json'
        logger.info(f"ä¿å­˜ä¿¡å·åˆ° {signals_file}ï¼ˆä¸­æ–‡å…³é”®å­—ï¼ŒåŒ—äº¬æ—¶é—´ï¼‰")
        from utils.json_i18n import translate_keys_to_chinese
        from utils.time_utils import convert_dict_times_to_beijing
        
        enhanced_cn = translate_keys_to_chinese(enhanced)
        # è½¬æ¢æ‰€æœ‰æ—¶é—´ä¸ºåŒ—äº¬æ—¶é—´
        enhanced_cn = [convert_dict_times_to_beijing(signal) for signal in enhanced_cn]
        
        with open(signals_file, 'w', encoding='utf8') as f:
            json.dump(enhanced_cn, f, ensure_ascii=False, indent=2, default=str)
        
        # 4. è¿è¡Œå›æµ‹
        logger.info("è¿è¡Œå›æµ‹...")
        # ä½¿ç”¨äº¤æ˜“æ¨¡å¼é…ç½®çš„å‚æ•°
        from utils.trading_mode import get_trading_mode_config
        data_interval = MARKET_INTERVAL if DATA_SOURCE in ['yahoo', 'csv'] else MARKET_TIMEFRAME
        mode_config = get_trading_mode_config(TRADING_MODE, data_interval)
        
        max_hold = int(os.getenv('BACKTEST_MAX_HOLD', mode_config['max_hold']))
        atr_stop = float(os.getenv('BACKTEST_ATR_STOP_MULT', mode_config['atr_stop_mult']))
        atr_target = float(os.getenv('BACKTEST_ATR_TARGET_MULT', mode_config['atr_target_mult']))
        min_rr = float(os.getenv('MIN_RISK_REWARD', mode_config['min_risk_reward']))
        min_llm = int(os.getenv('MIN_LLM_SCORE', mode_config['min_llm_score']))
        partial_tp_mult = float(os.getenv('BACKTEST_PARTIAL_TP_MULT', mode_config['partial_tp_mult']))
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é«˜é¢‘äº¤æ˜“æ¨¡å¼
        allow_multiple_trades_per_day = os.getenv('ALLOW_MULTIPLE_TRADES_PER_DAY', 'True').lower() == 'true'
        
        trades_df, metrics = simple_backtest(
            df, enhanced,
            max_hold=max_hold,
            atr_mult_stop=atr_stop,
            atr_mult_target=atr_target,
            min_llm_score=min_llm,
            min_risk_reward=min_rr,
            partial_tp_ratio=BACKTEST_PARTIAL_TP_RATIO,
            partial_tp_mult=partial_tp_mult,
            allow_multiple_trades_per_day=allow_multiple_trades_per_day
        )
        
        # 3.5. æ›´æ–°ä¿¡å·æ—¥å¿—ï¼Œæ·»åŠ æ­¢ç›ˆæ­¢æŸæ—¶é—´ä¿¡æ¯
        if not trades_df.empty and len(enhanced_cn) > 0:
            logger.info("æ›´æ–°ä¿¡å·æ—¥å¿—ï¼Œæ·»åŠ æ­¢ç›ˆæ­¢æŸæ—¶é—´ä¿¡æ¯...")
            # å»ºç«‹ä¿¡å·ç´¢å¼•åˆ°äº¤æ˜“è®°å½•çš„æ˜ å°„
            signal_to_trade = {}
            for trade_idx, trade in trades_df.iterrows():
                entry_idx = int(trade['entry_idx'])
                # æ‰¾åˆ°å¯¹åº”çš„ä¿¡å·ï¼ˆé€šè¿‡ entry_idx åŒ¹é…ï¼‰
                for signal_idx, signal in enumerate(enhanced):
                    rule = signal.get('rule', {})
                    signal_entry_idx = rule.get('idx', -1)
                    # entry_idx æ˜¯ signal_entry_idx + 1ï¼ˆå› ä¸ºå¼€å•åœ¨ä¿¡å·åä¸€ä¸ªå‘¨æœŸï¼‰
                    if signal_entry_idx + 1 == entry_idx:
                        signal_to_trade[signal_idx] = trade
                        break
            
            # æ›´æ–°ä¿¡å·æ—¥å¿—
            for signal_idx, trade in signal_to_trade.items():
                if signal_idx < len(enhanced_cn):
                    signal = enhanced_cn[signal_idx]
                    # æ·»åŠ äº¤æ˜“æ—¶é—´ä¿¡æ¯
                    stop_loss_val = trade.get('stop_loss', None)
                    full_tp_val = trade.get('full_take_profit', None)
                    partial_tp_val = trade.get('partial_take_profit', None)
                    
                    # å®‰å…¨åœ°è½¬æ¢ä¸º floatï¼ˆå¤„ç† None å’Œ NaN å€¼ï¼‰
                    def safe_float(val):
                        if val is None:
                            return None
                        try:
                            # å¦‚æœæ˜¯ pandas Series æˆ– numpy ç±»å‹ï¼Œå…ˆè½¬æ¢ä¸º Python ç±»å‹
                            if hasattr(val, 'item'):
                                val = val.item()
                            # æ£€æŸ¥æ˜¯å¦ä¸º NaNï¼ˆfloat('nan') æˆ– numpy.nanï¼‰
                            if isinstance(val, float) and val != val:  # NaN æ£€æŸ¥
                                return None
                            return float(val)
                        except (ValueError, TypeError):
                            return None
                    
                    signal['äº¤æ˜“æ—¶é—´'] = {
                        'å¼€å•æ—¶é—´': trade.get('entry_time', None),
                        'å¹³ä»“æ—¶é—´': trade.get('exit_time', None),
                        'éƒ¨åˆ†æ­¢ç›ˆæ—¶é—´': trade.get('partial_exit_time', None),
                        'æ­¢æŸä»·': safe_float(stop_loss_val),
                        'å…¨éƒ¨æ­¢ç›ˆä»·': safe_float(full_tp_val),
                        'éƒ¨åˆ†æ­¢ç›ˆä»·': safe_float(partial_tp_val)
                    }
            
            # é‡æ–°ä¿å­˜æ›´æ–°åçš„ä¿¡å·æ—¥å¿—ï¼ˆè½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼‰
            from utils.time_utils import convert_dict_times_to_beijing
            enhanced_cn = [convert_dict_times_to_beijing(signal) for signal in enhanced_cn]
            
            with open(signals_file, 'w', encoding='utf8') as f:
                json.dump(enhanced_cn, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"å·²æ›´æ–°ä¿¡å·æ—¥å¿—ï¼Œæ·»åŠ äº† {len(signal_to_trade)} ä¸ªäº¤æ˜“çš„æ­¢ç›ˆæ­¢æŸæ—¶é—´ä¿¡æ¯ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰")
        
        # 5. è¾“å‡ºç»“æœ
        from utils.i18n import format_metric_value
        logger.info("=" * 60)
        logger.info("å›æµ‹ç»“æœæ±‡æ€»:")
        for k, v in metrics.items():
            logger.info(format_metric_value(k, v))
        logger.info("=" * 60)
        
        # å›æµ‹æ¨¡å¼ï¼šéªŒè¯æ˜¯å¦è¾¾åˆ°ç›®æ ‡
        if backtest_mode:
            total_trades = metrics.get('total_trades', 0)
            if isinstance(df.index, pd.DatetimeIndex) and len(df) > 0:
                time_span_days = (df.index[-1] - df.index[0]).days
                time_span_months = time_span_days / 30
            else:
                time_span_months = 0
            
            logger.info("=" * 60)
            logger.info("å›æµ‹ç›®æ ‡éªŒè¯:")
            logger.info(f"  æ•°æ®æ—¶é—´è·¨åº¦: {time_span_months:.1f} ä¸ªæœˆ {'âœ…' if time_span_months >= 6 else 'âŒ'}")
            logger.info(f"  äº¤æ˜“æ•°é‡: {total_trades} ç¬” {'âœ…' if total_trades >= 200 else 'âŒ'}")
            if time_span_months < 6:
                logger.warning(f"  âš ï¸ æ•°æ®æ—¶é—´è·¨åº¦ä¸è¶³6ä¸ªæœˆï¼Œå»ºè®®è®¾ç½® BACKTEST_MONTHS=6")
            if total_trades < 200:
                logger.warning(f"  âš ï¸ äº¤æ˜“æ•°é‡ä¸è¶³200ç¬”ï¼Œå»ºè®®è¿›ä¸€æ­¥é™ä½è¿‡æ»¤é˜ˆå€¼")
            logger.info("=" * 60)
        
        # è¾“å‡ºæ¯ç¬”äº¤æ˜“çš„è¯¦ç»†ä¿¡æ¯
        if not trades_df.empty:
            logger.info("\näº¤æ˜“æ˜ç»†:")
            logger.info("-" * 80)
            for idx, trade in trades_df.iterrows():
                logger.info(f"äº¤æ˜“ #{idx+1}:")
                logger.info(f"  å¼€å•ä»·: {trade['entry_price']:.4f}")
                logger.info(f"  æ­¢æŸä»·: {trade['stop_loss']:.4f}")
                if 'partial_take_profit' in trade and pd.notna(trade['partial_take_profit']):
                    logger.info(f"  éƒ¨åˆ†æ­¢ç›ˆä»·: {trade['partial_take_profit']:.4f}")
                logger.info(f"  å…¨éƒ¨æ­¢ç›ˆä»·: {trade['full_take_profit']:.4f}")
                logger.info(f"  å¹³ä»“ä»·: {trade['exit_price']:.4f}")
                logger.info(f"  æ”¶ç›Šç‡: {trade['return']:.2%}")
                if 'partial_exited' in trade and pd.notna(trade.get('partial_exited')) and trade['partial_exited']:
                    logger.info(f"  éƒ¨åˆ†æ­¢ç›ˆ: æ˜¯ (åœ¨ç´¢å¼• {int(trade['partial_exit_idx'])} ä»¥ {trade['partial_exit_price']:.4f} å¹³ä»“)")
                logger.info(f"  ä¿¡å·ç±»å‹: {trade['rule_type']}, LLMè¯„åˆ†: {int(trade['llm_score'])}")
                logger.info("-" * 80)
        
        # 6. ä¿å­˜æ–‡ä»¶
        trades_file = output_dir / 'trades.csv'
        
        logger.info(f"ä¿å­˜äº¤æ˜“è®°å½•åˆ° {trades_file}")
        trades_df.to_csv(trades_file, index=False)
        
        # æ³¨æ„ï¼šsample_data.csv å·²åœ¨æ•°æ®è·å–æ—¶ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶
        # è¿™é‡Œä¸å†é‡å¤ä¿å­˜ï¼Œå› ä¸ºåŸå§‹Kçº¿æ•°æ®å·²ç»åœ¨è·å–æ—¶ä¿å­˜
        # å¦‚æœéœ€è¦åœ¨å¤„ç†åçš„æ•°æ®ï¼ˆåŒ…å«æŠ€æœ¯æŒ‡æ ‡ï¼‰ä¹Ÿä¿å­˜ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
        # data_file = output_dir / 'sample_data.csv'
        # logger.info(f"ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ° {data_file}")
        # df.to_csv(data_file)
        
        # 7. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’ŒæŠ¥å‘Š
        try:
            logger.info("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’ŒæŠ¥å‘Š...")
            chart_file = output_dir / 'trading_chart.png'
            plot_price_with_signals(df, enhanced, output_path=str(chart_file))
            
            if not trades_df.empty:
                backtest_chart_file = output_dir / 'backtest_results.png'
                plot_backtest_results(trades_df, output_path=str(backtest_chart_file))
            
            report_file = output_dir / 'analysis_report.txt'
            generate_report(df, enhanced, trades_df, metrics, output_path=str(report_file))
        except Exception as e:
            logger.warning(f"ç”Ÿæˆå¯è§†åŒ–å¤±è´¥: {e}")
        
        logger.info("=" * 60)
        logger.info("æ‰€æœ‰æ–‡ä»¶ä¿å­˜æˆåŠŸï¼")
        logger.info(f"è¾“å‡ºç›®å½•: {output_dir.absolute()}")
        logger.info("=" * 60)
        
        return 0
        
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        logger.error(f"å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return 1

if __name__ == '__main__':
    sys.exit(main())
