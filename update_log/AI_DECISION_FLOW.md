# AI å†³ç­–æµç¨‹è¯´æ˜

## ğŸ“ AI å†³ç­–åœ¨é¡¹ç›®ä¸­çš„ä½¿ç”¨ä½ç½®

### 1. ä¿¡å·å¢å¼ºé˜¶æ®µï¼ˆ`strategy/strategy_runner.py`ï¼‰

**ä½ç½®**ï¼š`strategy/strategy_runner.py` ç¬¬ 64-77 è¡Œ

**åŠŸèƒ½**ï¼šå¯¹æ¯ä¸ªæ£€æµ‹åˆ°çš„äº¤æ˜“ä¿¡å·ï¼Œè°ƒç”¨ AI è¿›è¡Œåˆ†æå’Œè¯„åˆ†

```python
# å¯¹æ¯ä¸ªä¿¡å·æ„å»ºç‰¹å¾åŒ…
packet = build_feature_packet(df, idx)

# è°ƒç”¨ AI è¿›è¡Œä¿¡å·è§£é‡Š
llm_out = interpret_with_llm(
    packet, 
    provider=LLM_PROVIDER, 
    model=OPENAI_MODEL, 
    use_llm=use_llm,
    temperature=OPENAI_TEMPERATURE,
    max_tokens=OPENAI_MAX_TOKENS
)

# å°† AI å†³ç­–é™„åŠ åˆ°ä¿¡å·ä¸­
enhanced_signals.append({
    'rule': s,                    # åŸå§‹è§„åˆ™ä¿¡å·
    'feature_packet': packet,     # ç‰¹å¾æ•°æ®
    'llm': llm_out               # AI å†³ç­–ç»“æœ â­
})
```

**AI è¾“å…¥**ï¼šç‰¹å¾åŒ…ï¼ˆfeature_packetï¼‰ï¼ŒåŒ…å«ï¼š
- è¶‹åŠ¿æ–¹å‘ï¼ˆtrendï¼‰
- EMA æ’åˆ—ï¼ˆema_alignmentï¼‰
- æ›´é«˜é«˜ç‚¹/æ›´é«˜ä½ç‚¹ï¼ˆhigher_highs/higher_lowsï¼‰
- é‡èƒ½çˆ†å‘ï¼ˆvolume_spikeï¼‰
- çªç ´ï¼ˆbreakoutï¼‰
- RSI èƒŒç¦»ï¼ˆrsi_divergenceï¼‰
- ATR æ³¢åŠ¨ç‡
- æˆäº¤é‡æ¯”ç‡
- å½“å‰ä»·æ ¼

**AI è¾“å‡º**ï¼šJSON æ ¼å¼çš„å†³ç­–ç»“æœï¼ŒåŒ…å«ï¼š
- `signal`: äº¤æ˜“ä¿¡å·ï¼ˆ'Long', 'Short', 'Neutral', 'Hold'ï¼‰
- `score`: è¯„åˆ†ï¼ˆ0-100ï¼‰
- `confidence`: ç½®ä¿¡åº¦ï¼ˆ'High', 'Medium', 'Low'ï¼‰
- `trend_structure`: è¶‹åŠ¿ç»“æ„
- `explanation`: è§£é‡Šè¯´æ˜
- `risk`: é£é™©è¯„ä¼°

### 2. AI å†³ç­–æ ¸å¿ƒå‡½æ•°ï¼ˆ`ai_agent/signal_interpret.py`ï¼‰

**ä½ç½®**ï¼š`ai_agent/signal_interpret.py` ç¬¬ 9-49 è¡Œ

**åŠŸèƒ½**ï¼šè°ƒç”¨ LLM APIï¼Œå°†æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾è½¬æ¢ä¸ºäº¤æ˜“å†³ç­–

```python
def interpret_with_llm(feature_packet, provider='openai', model='gpt-4o-mini', 
                       use_llm=True, temperature=0.0, max_tokens=400):
    """
    æŠŠç»“æ„åŒ–ç‰¹å¾ä¼ ç»™ LLMï¼Œè§£æè¿”å›çš„ JSONã€‚
    è‹¥æ— æ³•è°ƒç”¨ LLM æˆ–è§£æå¤±è´¥ï¼Œè¿”å›ç®€å•å¯å‘å¼èšåˆã€‚
    """
    if not use_llm:
        # é™çº§ï¼šä½¿ç”¨å¯å‘å¼è§„åˆ™
        return fallback_heuristic(feature_packet)
    
    # æ„å»º Prompt
    prompt = MARKET_STRUCTURE_PROMPT + "\n\nç‰¹å¾æ•°æ®ï¼š\n" + json.dumps(feature_packet, ensure_ascii=False)
    
    # è°ƒç”¨ LLM API â­
    txt = ask_llm(prompt, provider=provider, model=model)
    
    # è§£æ LLM è¿”å›çš„ JSON
    parsed = json.loads(txt.strip())
    return parsed
```

**Prompt æ¨¡æ¿**ï¼š`ai_agent/llm_prompt.py`
- åŒ…å«å¸‚åœºç»“æ„åˆ†æçš„ Prompt
- æŒ‡å¯¼ LLM å¦‚ä½•åˆ†ææŠ€æœ¯æŒ‡æ ‡
- è¦æ±‚è¿”å›ç»“æ„åŒ–çš„ JSON å†³ç­–

### 3. å›æµ‹æ‰§è¡Œé˜¶æ®µï¼ˆ`backtest/simulator.py`ï¼‰

**ä½ç½®**ï¼š`backtest/simulator.py` ç¬¬ 24-40 è¡Œ

**åŠŸèƒ½**ï¼šä½¿ç”¨ AI å†³ç­–æ¥è¿‡æ»¤å’Œæ‰§è¡Œäº¤æ˜“

```python
for item in enhanced_signals:
    s = item['rule']           # åŸå§‹è§„åˆ™ä¿¡å·
    llm = item.get('llm', {})  # AI å†³ç­–ç»“æœ â­
    
    # ä» AI å†³ç­–ä¸­æå–ä¿¡å·å’Œè¯„åˆ†
    signal = llm.get('signal', 'Neutral') if isinstance(llm, dict) else 'Neutral'
    raw_score = llm.get('score', 0)
    score = int(raw_score)
    
    # â­ AI å†³ç­–è¿‡æ»¤ï¼šåªæ‰§è¡Œ AI æ¨èçš„ Long ä¿¡å·ï¼Œä¸”è¯„åˆ† >= 40
    if signal != 'Long' or score < min_llm_score:
        continue  # è·³è¿‡ä¸ç¬¦åˆ AI å†³ç­–çš„ä¿¡å·
    
    # æ‰§è¡Œäº¤æ˜“...
```

**AI å†³ç­–çš„ä½œç”¨**ï¼š
1. **ä¿¡å·è¿‡æ»¤**ï¼šåªæ‰§è¡Œ AI æ¨èä¸º 'Long' çš„ä¿¡å·
2. **è¯„åˆ†é˜ˆå€¼**ï¼šåªæ‰§è¡Œè¯„åˆ† >= `MIN_LLM_SCORE`ï¼ˆé»˜è®¤40ï¼‰çš„ä¿¡å·
3. **å†³ç­–ä¾æ®**ï¼šAI çš„ `signal` å’Œ `score` æ˜¯å›æµ‹æ‰§è¡Œçš„å…³é”®åˆ¤æ–­æ¡ä»¶

### 4. LLM å®¢æˆ·ç«¯ï¼ˆ`ai_agent/llm_client.py`ï¼‰

**ä½ç½®**ï¼š`ai_agent/llm_client.py` ç¬¬ 9-35 è¡Œ

**åŠŸèƒ½**ï¼šå®é™…è°ƒç”¨ OpenAI API

```python
def call_openai_chat(prompt, model='gpt-4o-mini', temperature=0.0, max_tokens=400):
    """
    è°ƒç”¨ OpenAI ChatCompletion API
    """
    client = get_openai_client()
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=temperature,
        max_tokens=max_tokens
    )
    txt = response.choices[0].message.content
    return txt
```

## ğŸ”„ å®Œæ•´å†³ç­–æµç¨‹

```
1. æ£€æµ‹è§„åˆ™ä¿¡å·
   â””â”€> signal_rules.py: detect_rules()
       â””â”€> è¾“å‡ºï¼šåŸå§‹ä¿¡å·åˆ—è¡¨

2. æ„å»ºç‰¹å¾åŒ…
   â””â”€> strategy_runner.py: build_feature_packet()
       â””â”€> è¾“å‡ºï¼šç‰¹å¾å­—å…¸ï¼ˆåŒ…å« EMAã€RSIã€æˆäº¤é‡ç­‰ï¼‰

3. AI åˆ†æå†³ç­– â­
   â””â”€> signal_interpret.py: interpret_with_llm()
       â””â”€> llm_client.py: call_openai_chat()
           â””â”€> è¾“å‡ºï¼šAI å†³ç­–ï¼ˆsignal, score, confidence, explanationï¼‰

4. ä¿¡å·å¢å¼º
   â””â”€> strategy_runner.py: run_strategy()
       â””â”€> è¾“å‡ºï¼šå¢å¼ºä¿¡å·åˆ—è¡¨ï¼ˆåŒ…å« AI å†³ç­–ï¼‰

5. å›æµ‹æ‰§è¡Œï¼ˆä½¿ç”¨ AI å†³ç­–è¿‡æ»¤ï¼‰â­
   â””â”€> simulator.py: simple_backtest()
       â””â”€> æ ¹æ® AI çš„ signal å’Œ score å†³å®šæ˜¯å¦æ‰§è¡Œäº¤æ˜“
           â””â”€> è¾“å‡ºï¼šäº¤æ˜“è®°å½•å’Œå›æµ‹æŒ‡æ ‡
```

## ğŸ¯ AI å†³ç­–çš„å…³é”®ä½œç”¨

### 1. ä¿¡å·è´¨é‡è¯„ä¼°
- AI å¯¹æ¯ä¸ªæŠ€æœ¯æŒ‡æ ‡ä¿¡å·è¿›è¡Œè¯„åˆ†ï¼ˆ0-100ï¼‰
- è¯„ä¼°ä¿¡å·çš„å¯é æ€§å’Œç½®ä¿¡åº¦

### 2. äº¤æ˜“æ–¹å‘åˆ¤æ–­
- AI å†³å®šæ˜¯ 'Long'ï¼ˆåšå¤šï¼‰ã€'Short'ï¼ˆåšç©ºï¼‰è¿˜æ˜¯ 'Neutral'ï¼ˆä¸­æ€§ï¼‰
- å½“å‰å›æµ‹ç³»ç»Ÿåªæ‰§è¡Œ 'Long' ä¿¡å·

### 3. é£é™©åˆ†æ
- AI æä¾›é£é™©è¯„ä¼°å’Œè§£é‡Š
- å¸®åŠ©ç†è§£ä¸ºä»€ä¹ˆåšå‡ºè¿™ä¸ªå†³ç­–

### 4. ä¿¡å·è¿‡æ»¤
- åœ¨å›æµ‹ä¸­ï¼Œåªæœ‰ AI æ¨èä¸”è¯„åˆ† >= 40 çš„ä¿¡å·æ‰ä¼šè¢«æ‰§è¡Œ
- è¿™å¤§å¤§å‡å°‘äº†å‡ä¿¡å·çš„å½±å“

## ğŸ“Š AI å†³ç­–ç¤ºä¾‹

**è¾“å…¥ç‰¹å¾åŒ…**ï¼š
```json
{
  "trend": "up",
  "ema_alignment": true,
  "higher_highs": true,
  "volume_spike": true,
  "breakout": false,
  "rsi_divergence": null,
  "atr": 50.5,
  "vol_ratio": 2.1,
  "close": 30000
}
```

**AI è¾“å‡ºå†³ç­–**ï¼š
```json
{
  "signal": "Long",
  "score": 75,
  "confidence": "High",
  "trend_structure": "Bull",
  "explanation": "Strong uptrend with EMA alignment, volume confirmation",
  "risk": "Medium"
}
```

**å›æµ‹æ‰§è¡Œ**ï¼š
- âœ… ä¿¡å· = 'Long'ï¼Œè¯„åˆ† = 75 >= 40
- âœ… æ‰§è¡Œäº¤æ˜“

## âš™ï¸ é…ç½®æ§åˆ¶

### å¯ç”¨/ç¦ç”¨ AI å†³ç­–

```bash
# å¯ç”¨ AI å†³ç­–ï¼ˆé»˜è®¤ï¼‰
USE_LLM=True python3 main.py

# ç¦ç”¨ AI å†³ç­–ï¼ˆä½¿ç”¨å¯å‘å¼è§„åˆ™ï¼‰
USE_LLM=False python3 main.py
```

### è°ƒæ•´ AI å†³ç­–é˜ˆå€¼

```bash
# åªæ‰§è¡Œè¯„åˆ† >= 50 çš„ä¿¡å·ï¼ˆé»˜è®¤40ï¼‰
MIN_LLM_SCORE=50 python3 main.py
```

### AI æ¨¡å‹é…ç½®

```bash
# ä½¿ç”¨ä¸åŒçš„æ¨¡å‹
OPENAI_MODEL=gpt-4o python3 main.py

# è°ƒæ•´æ¸©åº¦å‚æ•°ï¼ˆå½±å“éšæœºæ€§ï¼‰
OPENAI_TEMPERATURE=0.2 python3 main.py
```

## ğŸ” æŸ¥çœ‹ AI å†³ç­–ç»“æœ

AI å†³ç­–ç»“æœä¿å­˜åœ¨ `signals_log.json` æ–‡ä»¶ä¸­ï¼š

```json
[
  {
    "rule": {
      "type": "long_structure",
      "score": 4,
      "confidence": "high",
      "idx": 123
    },
    "feature_packet": {
      "trend": "up",
      "ema_alignment": true,
      ...
    },
    "llm": {                    // â­ AI å†³ç­–ç»“æœ
      "signal": "Long",
      "score": 75,
      "confidence": "High",
      "explanation": "...",
      "risk": "Medium"
    }
  }
]
```

## ğŸ’¡ æ€»ç»“

**AI å†³ç­–åœ¨é¡¹ç›®ä¸­çš„æ ¸å¿ƒä½ç½®**ï¼š

1. **`strategy/strategy_runner.py`** - è°ƒç”¨ AI åˆ†ææ¯ä¸ªä¿¡å·
2. **`ai_agent/signal_interpret.py`** - AI å†³ç­–çš„æ ¸å¿ƒå‡½æ•°
3. **`ai_agent/llm_client.py`** - å®é™…è°ƒç”¨ OpenAI API
4. **`backtest/simulator.py`** - ä½¿ç”¨ AI å†³ç­–è¿‡æ»¤å’Œæ‰§è¡Œäº¤æ˜“

**AI å†³ç­–çš„ä½œç”¨**ï¼š
- âœ… è¯„ä¼°ä¿¡å·è´¨é‡
- âœ… å†³å®šäº¤æ˜“æ–¹å‘
- âœ… æä¾›é£é™©åˆ†æ
- âœ… è¿‡æ»¤ä½è´¨é‡ä¿¡å·

**å…³é”®é…ç½®**ï¼š
- `USE_LLM`: æ˜¯å¦å¯ç”¨ AI å†³ç­–
- `MIN_LLM_SCORE`: AI è¯„åˆ†æœ€ä½é˜ˆå€¼ï¼ˆé»˜è®¤40ï¼‰
- `OPENAI_MODEL`: ä½¿ç”¨çš„ AI æ¨¡å‹
- `OPENAI_TEMPERATURE`: AI æ¸©åº¦å‚æ•°

